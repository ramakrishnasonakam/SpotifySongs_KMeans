# -*- coding: utf-8 -*-
"""SpotifySongs_KMeans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13_2CQgDwXkeFMTqV3GD38H1XB_QpFGyE
"""

import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Spotify_Data.csv')
df.head()

df.info()

print(df.shape)
print('\n', df.isnull().sum())

df = df.drop(columns=['cover_url'])
df.head()

df.columns

df = df.drop(columns=['track_name', 'artist_count', 'in_spotify_playlists', 'in_spotify_charts', 'in_apple_playlists', 'in_apple_charts' ,'in_deezer_playlists', 'in_deezer_charts', 'in_shazam_charts'])
# df = df[df['streams'] > 0]

df.head()

df = df.drop(columns=['released_day'])
df.head()

df = df.dropna(subset=['bpm', 'key'])

df.info()

df = df[df['streams'] != 'BPM110KeyAModeMajorDanceability53Valence75Energy69Acousticness7Instrumentalness0Liveness17Speechiness3']
df['streams'] = pd.to_numeric(df['streams'], errors='coerce')
df.dropna(inplace=True)

df.info()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,6))
sns.heatmap(df.corr(numeric_only=True), annot=True, fmt= '.2f', cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

sns.pairplot(df, vars=['bpm','energy_%','valence_%','danceability_%'], plot_kws={'alpha':0.6})
plt.suptitle('Feature Pair Relationships', y=1.02)
plt.show()

for col in ['energy_%','danceability_%','valence_%','acousticness_%']:
    plt.figure()
    sns.scatterplot(x=df[col], y=df['streams'])
    plt.title(f'Streams vs {col}')
    plt.show()

df['bpm_bin'] = pd.cut(df['bpm'], bins=[0, 80, 100, 120, 140, 160, 200], labels=['<80','80-100','100-120','120-140','140-160','160+'])
summary = df.groupby(['key', 'bpm_bin'])['streams'].agg(['mean', 'median', 'count']).reset_index()

summary.head()

plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='bpm', y='streams', hue='key', palette='Spectral', alpha=0.7)
sns.regplot(data=df, x='bpm', y='streams', scatter=False, color='black', lowess=True)
plt.title('BPM vs Streams by Key')
plt.xlabel('Beats Per Minute (BPM)')
plt.ylabel('Streams')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

avg_streams_key = df.groupby('key', as_index=False)['streams'].mean().sort_values('streams', ascending=False)

print("Average Streams by Musical Key:")
print(avg_streams_key)

plt.figure(figsize=(8,5))
sns.barplot(data=avg_streams_key, x='key', y='streams', palette='viridis')
plt.title('Average Streams by Musical Key')
plt.xlabel('Musical Key')
plt.ylabel('Average Streams')
plt.tight_layout()
plt.show()

avg_streams_bpm = df.groupby('bpm_bin', as_index=False)['streams'].mean().sort_values('streams', ascending=False)

plt.figure(figsize=(8, 5))
sns.barplot(data=avg_streams_bpm, x='bpm_bin', y='streams', palette='viridis')
plt.title('Average Streams by Beats Per Minute (BPM)')
plt.xlabel('Beats Per Minute (BPM)')
plt.ylabel('Average Streams')
plt.tight_layout()
plt.show()

nums_cols = ['bpm', 'danceability_%', 'valence_%', 'energy_%', 'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%']

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[nums_cols] = scaler.fit_transform(df[nums_cols])

features = ['bpm', 'danceability_%', 'valence_%', 'energy_%', 'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%']
X = df[features]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

inertia, sil = [], []
for k in range(2,11):
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X_scaled)
    inertia.append(km.inertia_)
    sil.append(silhouette_score(X_scaled, km.labels_))

plt.plot(range(2,11), inertia, marker='o')
plt.title('Elbow Method')
plt.xlabel('k')
plt.ylabel('Inertia')
plt.show()

plt.plot(range(2,11), sil, marker='o', color='green')
plt.title('Silhouette Scores')
plt.xlabel('k')
plt.ylabel('Silhouette')
plt.show()

kmeans = KMeans(n_clusters=4, random_state=42)
df['cluster'] = kmeans.fit_predict(X_scaled)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca_result = pca.fit_transform(X_scaled)
df['PCA1'], df['PCA2'] = pca_result[:,0], pca_result[:,1]
plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='PCA1', y='PCA2', hue='cluster', palette='viridis', alpha=0.8)
plt.title('K-Means Clusters of Spotify Songs')
plt.show()
cluster_profile = df.groupby('cluster')[X.columns].mean().round(2)
print(cluster_profile)

kmeans = KMeans(n_clusters=5, random_state=42)
df['k5_cluster'] = kmeans.fit_predict(X_scaled)

pca = PCA(n_components=2)
pca_result = pca.fit_transform(X_scaled)
df['k5_PCA1'], df['k5_PCA2'] = pca_result[:,0], pca_result[:,1]
plt.figure(figsize=(6,4))
sns.scatterplot(data=df, x='k5_PCA1', y='k5_PCA2', hue='cluster', palette='viridis', alpha=0.8)
plt.title('K-Means Clusters of Spotify Songs')
plt.show()
cluster_profile = df.groupby('k5_cluster')[X.columns].mean().round(2)
print(cluster_profile)

from sklearn.mixture import GaussianMixture
gmm = GaussianMixture(n_components=4, random_state=42)
df['gmm_cluster'] = gmm.fit_predict(X_scaled)

df['gmm_cluster'].value_counts()
probs = gmm.predict_proba(X_scaled)
df[[f'prob_cluster_{i}' for i in range(4)]] = probs
pd.crosstab(df['cluster'], df['gmm_cluster'])
gmm_profile = df.groupby('gmm_cluster')[['bpm','danceability_%','energy_%','valence_%','acousticness_%','speechiness_%','instrumentalness_%']].mean().round(2)
print(gmm_profile)
pca = PCA(n_components=2)
pca_result = pca.fit_transform(X_scaled)
df['PCA1'], df['PCA2'] = pca_result[:,0], pca_result[:,1]

plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='PCA1', y='PCA2', hue='gmm_cluster', palette='viridis', alpha=0.8)
plt.title('Gaussian Mixture Model Clusters (PCA Projection)')
plt.show()

print('AIC:', gmm.aic(X_scaled))
print('BIC:', gmm.bic(X_scaled))